import pandas as pd
import re
import json
import os
import glob
import random
from collections import Counter

# --- Cáº¤U HÃŒNH ---
INPUT_DATA_PATH = '../data/dataset' 

# --- Bá»˜ Tá»ª KHÃ“A Má» Rá»˜NG (RICH KEYWORDS) ---
# ÄÃ¢y lÃ  bá»™ lá»c Ä‘á»ƒ phÃ¢n loáº¡i cÃ¢u há»i vÃ o cÃ¡c nhÃ³m chá»§ Ä‘á»
TOPIC_KEYWORDS = {
    "HONNHAN": [
        "ly hÃ´n", "li hÃ´n", "ly dá»‹", "li dá»‹", "káº¿t hÃ´n", "hÃ´n nhÃ¢n", 
        "tÃ i sáº£n chung", "tÃ i sáº£n riÃªng", "chia tÃ i sáº£n", 
        "nuÃ´i con", "quyá»n nuÃ´i con", "cáº¥p dÆ°á»¡ng", "trá»£ cáº¥p nuÃ´i con",
        "Ä‘Äƒng kÃ½ káº¿t hÃ´n", "há»§y hÃ´n", "chung sá»‘ng nhÆ° vá»£ chá»“ng",
        "báº¡o lá»±c gia Ä‘Ã¬nh", "ngÆ°á»i thá»© ba", "ngoáº¡i tÃ¬nh", 
        "con riÃªng", "con chung", "tranh cháº¥p nuÃ´i con", "thá»«a káº¿", 
        "di chÃºc", "tÆ°á»›c quyá»n nuÃ´i con", "ly thÃ¢n"
    ],
    "DATDAI": [
        "sá»• Ä‘á»", "sá»• há»“ng", "giáº¥y chá»©ng nháº­n", "quyá»n sá»­ dá»¥ng Ä‘áº¥t",
        "chuyá»ƒn nhÆ°á»£ng Ä‘áº¥t", "sang tÃªn", "tÃ¡ch thá»­a", "há»£p thá»­a",
        "mua bÃ¡n Ä‘áº¥t", "giÃ¡ Ä‘áº¥t", "thá»• cÆ°", "Ä‘áº¥t ao", "Ä‘áº¥t vÆ°á»n",
        "chuyá»ƒn má»¥c Ä‘Ã­ch", "Ä‘á»n bÃ¹", "giáº£i tá»a", "quy hoáº¡ch",
        "tranh cháº¥p Ä‘áº¥t", "láº¥n chiáº¿m Ä‘áº¥t", "táº·ng cho Ä‘áº¥t",
        "Ä‘áº¥t dá»± Ã¡n", "Ä‘áº¥t nÃ´ng nghiá»‡p", "Ä‘áº¥t phi nÃ´ng nghiá»‡p",
        "Ä‘áº¥t á»Ÿ", "sá»• Ä‘á» giáº£", "xÃ¢y dá»±ng khÃ´ng phÃ©p"
    ],
    "GIAOTHONG": [
        "giao thÃ´ng", "vi pháº¡m giao thÃ´ng", "xá»­ pháº¡t", "pháº¡t nguá»™i",
        "báº±ng lÃ¡i", "gplx", "giáº¥y phÃ©p lÃ¡i xe", 
        "xe mÃ¡y", "Ã´ tÃ´", "Ä‘Äƒng kiá»ƒm", "tem Ä‘Äƒng kiá»ƒm",
        "biá»ƒn sá»‘", "biá»ƒn kiá»ƒm soÃ¡t", 
        "ná»“ng Ä‘á»™ cá»“n", "thá»•i ná»“ng Ä‘á»™ cá»“n", 
        "tÆ°á»›c báº±ng", "tÆ°á»›c giáº¥y phÃ©p", 
        "vÆ°á»£t Ä‘Ã¨n Ä‘á»", "Ä‘i sai lÃ n", "dá»«ng Ä‘á»— sai quy Ä‘á»‹nh",
        "tai náº¡n giao thÃ´ng"
    ],
    "CUTRU": [
        "cÆ° trÃº", "táº¡m trÃº", "thÆ°á»ng trÃº", "há»™ kháº©u", 
        "cáº¯t kháº©u", "nháº­p kháº©u", "táº¡m váº¯ng",
        "cccd", "cÄƒn cÆ°á»›c", "cÄƒn cÆ°á»›c cÃ´ng dÃ¢n", 
        "cmnd", "chá»©ng minh nhÃ¢n dÃ¢n",
        "vneid", "Ä‘á»‹nh danh Ä‘iá»‡n tá»­",
        "Ä‘á»•i cccd", "máº¥t cccd", "lÃ m láº¡i cÄƒn cÆ°á»›c"
    ],
    "HINHSU": [
        "hÃ¬nh sá»±", "tá»™i pháº¡m", "truy tá»‘", "khá»Ÿi tá»‘", 
        "bá»‹ can", "bá»‹ cÃ¡o", "táº¡m giam", 
        "Ã¡n treo", "Ã¡n tÃ¹", "pháº¡t tÃ¹", 
        "trá»™m cáº¯p", "cÆ°á»›p", "giáº¿t ngÆ°á»i", "hiáº¿p dÃ¢m",
        "Ä‘Ã¡nh báº¡c", "tá»• chá»©c Ä‘Ã¡nh báº¡c", 
        "ma tÃºy", "sá»­ dá»¥ng ma tÃºy", "mua bÃ¡n ma tÃºy",
        "lá»«a Ä‘áº£o", "chiáº¿m Ä‘oáº¡t", "gÃ¢y thÆ°Æ¡ng tÃ­ch", 
        "báº¡o hÃ nh", "cÆ°á»¡ng Ä‘oáº¡t",
        "quáº¥y rá»‘i", "lÃ m nhá»¥c ngÆ°á»i khÃ¡c"
    ],
    "QUANSU": [
        "nghÄ©a vá»¥ quÃ¢n sá»±", "nghÄ©a vá»¥", "nháº­p ngÅ©", 
        "táº¡m hoÃ£n", "miá»…n nghÄ©a vá»¥", "Ä‘i bá»™ Ä‘á»™i", 
        "dÃ¢n quÃ¢n tá»± vá»‡", "khÃ¡m sá»©c khá»e", "xuáº¥t ngÅ©",
        "trá»‘n nghÄ©a vá»¥", "bá»‹ gá»i nháº­p ngÅ©"
    ],
    "DOANHNGHIEP": [
        "doanh nghiá»‡p", "cÃ´ng ty", "há»™ kinh doanh", 
        "Ä‘Äƒng kÃ½ kinh doanh", "giáº¥y phÃ©p kinh doanh",
        "thÃ nh láº­p cÃ´ng ty", "giáº£i thá»ƒ", "phÃ¡ sáº£n",
        "cá»• pháº§n", "vá»‘n Ä‘iá»u lá»‡", "gÃ³p vá»‘n",
        "tnhh", "cÃ´ng ty tnhh", "cÃ´ng ty cá»• pháº§n",
        "hÃ³a Ä‘Æ¡n Ä‘iá»‡n tá»­", "taxcode", "mÃ£ sá»‘ thuáº¿ doanh nghiá»‡p"
    ],
    "LAODONG": [
        "lao Ä‘á»™ng", "há»£p Ä‘á»“ng lao Ä‘á»™ng", "thá»­ viá»‡c",
        "sa tháº£i", "thÃ´i viá»‡c", "cháº¥m dá»©t há»£p Ä‘á»“ng",
        "tranh cháº¥p lao Ä‘á»™ng", "báº£o hiá»ƒm xÃ£ há»™i", "bhxh",
        "báº£o hiá»ƒm y táº¿", "bhyt", 
        "thai sáº£n", "nghá»‰ thai sáº£n",
        "á»‘m Ä‘au", "hÆ°u trÃ­", "tÄƒng ca", "lÃ m thÃªm giá»",
        "lÆ°Æ¡ng", "lÆ°Æ¡ng cÆ¡ báº£n", "báº£ng lÆ°Æ¡ng",
        "tháº¥t nghiá»‡p"
    ],
    "THUE": [
        "thuáº¿", "thuáº¿ tncn", "thu nháº­p cÃ¡ nhÃ¢n", 
        "thuáº¿ tndn", "thuáº¿ doanh nghiá»‡p", 
        "kÃª khai thuáº¿", "ná»™p thuáº¿", "hoÃ n thuáº¿", 
        "hÃ³a Ä‘Æ¡n", "hÃ³a Ä‘Æ¡n Ä‘iá»‡n tá»­", 
        "lá»‡ phÃ­ trÆ°á»›c báº¡", "mÃ£ sá»‘ thuáº¿", "mst cÃ¡ nhÃ¢n"
    ],
    "HANHCHINH": [
        "hÃ nh chÃ­nh", "xá»­ pháº¡t hÃ nh chÃ­nh", 
        "khiáº¿u náº¡i", "tá»‘ cÃ¡o", 
        "cÃ´ng chá»©ng", "chá»©ng thá»±c",
        "á»§y ban", "á»§y ban nhÃ¢n dÃ¢n", 
        "giáº¥y khai sinh", "trÃ­ch lá»¥c", "há»™ tá»‹ch", 
        "giáº¥y tá» tÃ¹y thÃ¢n", "máº¥t giáº¥y tá»", 
        "xin cáº¥p láº¡i", "thá»§ tá»¥c hÃ nh chÃ­nh"
    ],
    "DANSU": [
    "dÃ¢n sá»±", "há»£p Ä‘á»“ng", "bá»“i thÆ°á»ng", "thiá»‡t háº¡i",
    "tranh cháº¥p há»£p Ä‘á»“ng", "á»§y quyá»n", "vay tiá»n", "ná»£", 
    "Ä‘Ã²i ná»£", "lÃ£i suáº¥t", "quyá»n dÃ¢n sá»±"
    ]
    "CONGNGHE": [
        "lá»«a Ä‘áº£o online", "scam", "hack", "an ninh máº¡ng",
        "lá»™ thÃ´ng tin", "Ä‘Ã¡nh cáº¯p dá»¯ liá»‡u", 
        "facebook bá»‹ hack", "máº¥t tÃ i khoáº£n", "lá»«a Ä‘áº£o qua máº¡ng"
    ]

}

def clean_text(text):
    """LÃ m sáº¡ch vÄƒn báº£n cÆ¡ báº£n"""
    text = str(text).strip()
    # XÃ³a cÃ¡c kÃ½ tá»± rÃ¡c Ä‘áº§u cÃ¢u (gáº¡ch Ä‘áº§u dÃ²ng, sá»‘ thá»© tá»±)
    text = re.sub(r'^[-â€¢*+\d\.]+\s*', '', text)
    return text

def classify_question(question):
    """PhÃ¢n loáº¡i cÃ¢u há»i vÃ o chá»§ Ä‘á» dá»±a trÃªn tá»« khÃ³a"""
    q_lower = question.lower()
    for topic, keywords in TOPIC_KEYWORDS.items():
        for kw in keywords:
            if kw in q_lower:
                return topic
    return "DEFAULT"

def analyze_unclassified(questions):
    """PhÃ¢n tÃ­ch cÃ¡c cÃ¢u chÆ°a phÃ¢n loáº¡i Ä‘á»ƒ tÃ¬m tá»« khÃ³a má»›i"""
    print("\n--- ğŸ” PHÃ‚N TÃCH Dá»® LIá»†U CHÆ¯A PHÃ‚N LOáº I (DEFAULT) ---")
    print("CÃ¡c tá»« khÃ³a xuáº¥t hiá»‡n nhiá»u nháº¥t trong nhÃ³m DEFAULT (Gá»£i Ã½ Ä‘á»ƒ báº¡n thÃªm vÃ o TOPIC_KEYWORDS):")
    
    all_words = []
    for q in questions:
        # TÃ¡ch tá»« Ä‘Æ¡n giáº£n
        words = re.findall(r'\w+', q.lower())
        # Lá»c tá»« quÃ¡ ngáº¯n (nhÆ°: lÃ , vÃ , cÃ³...)
        words = [w for w in words if len(w) > 3] 
        all_words.extend(words)
    
    counter = Counter(all_words)
    top_20 = counter.most_common(20)
    
    for word, count in top_20:
        print(f"   - {word}: {count} láº§n")
    print("-" * 60)

def load_data_optimized(path):
    print(f"-> Äang kiá»ƒm tra Ä‘Æ°á»ng dáº«n: {path}")
    try:
        if os.path.isdir(path):
            files = glob.glob(os.path.join(path, "*.parquet"))
            if not files: files = glob.glob(os.path.join(path, "**/*.parquet"), recursive=True)
            
            if not files:
                print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y file .parquet nÃ o.")
                return pd.DataFrame()
                
            print(f"-> PhÃ¡t hiá»‡n {len(files)} file Parquet. Äang Ä‘á»c...")
            df_list = []
            for f in files:
                try:
                    # Chá»‰ Ä‘á»c cá»™t question Ä‘á»ƒ tiáº¿t kiá»‡m RAM tá»‘i Ä‘a
                    df_part = pd.read_parquet(f, columns=['question'])
                    df_list.append(df_part)
                except: pass
            
            return pd.concat(df_list, ignore_index=True) if df_list else pd.DataFrame()

        elif os.path.isfile(path):
            if path.endswith('.parquet'): return pd.read_parquet(path, columns=['question'])
            elif path.endswith('.xlsx'): return pd.read_excel(path, usecols=['question'])
            elif path.endswith('.csv'): return pd.read_csv(path, usecols=['question'])
        
        return pd.DataFrame()

    except Exception as e:
        print(f"âŒ Lá»—i Ä‘á»c dá»¯ liá»‡u: {e}")
        return pd.DataFrame()

def main():
    print("="*60)
    print("   TOOL Táº O Gá»¢I Ã Tá»° Äá»˜NG (PHIÃŠN Báº¢N THÃ”NG MINH)")
    print("="*60)
    
    df = load_data_optimized(INPUT_DATA_PATH)
    
    if df.empty:
        print("âŒ KhÃ´ng Ä‘á»c Ä‘Æ°á»£c dá»¯ liá»‡u!")
        return

    total_rows = len(df)
    print(f"âœ… ÄÃ£ táº£i: {total_rows:,} cÃ¢u há»i.")
    
    # Náº¿u dá»¯ liá»‡u quÃ¡ lá»›n, láº¥y máº«u Ä‘á»ƒ xá»­ lÃ½ nhanh
    if total_rows > 100000:
        print("-> Dá»¯ liá»‡u lá»›n, láº¥y máº«u ngáº«u nhiÃªn 100,000 dÃ²ng Ä‘á»ƒ phÃ¢n tÃ­ch...")
        df = df.sample(n=100000, random_state=42)

    suggestions_map = {k: [] for k in TOPIC_KEYWORDS.keys()}
    suggestions_map["DEFAULT"] = []
    
    # Danh sÃ¡ch táº¡m Ä‘á»ƒ chá»©a cÃ¡c cÃ¢u Default phá»¥c vá»¥ phÃ¢n tÃ­ch
    default_questions_for_analysis = []

    count = 0
    for _, row in df.iterrows():
        question = clean_text(row.get('question', ''))
        
        # Lá»c cÃ¢u cÃ³ Ä‘á»™ dÃ i Ä‘áº¹p (Ä‘á»ƒ hiá»ƒn thá»‹ lÃªn chip)
        if 20 < len(question) < 65:
            if not re.search('[a-zA-Z]', question): continue
            
            topic = classify_question(question)
            
            # LÆ°u láº¡i cÃ¢u Default Ä‘á»ƒ phÃ¢n tÃ­ch sau
            if topic == "DEFAULT":
                default_questions_for_analysis.append(question)

            # ThÃªm vÃ o danh sÃ¡ch gá»£i Ã½ (chá»‰ cáº§n khoáº£ng 20 cÃ¢u má»—i loáº¡i Ä‘á»ƒ random)
            if len(suggestions_map[topic]) < 20:
                formatted_q = question[0].upper() + question[1:].rstrip('?.')
                if formatted_q not in suggestions_map[topic]:
                    suggestions_map[topic].append(formatted_q)
    
    # --- PHÃ‚N TÃCH Dá»® LIá»†U CÃ’N SÃ“T ---
    if len(default_questions_for_analysis) > 0:
        # PhÃ¢n tÃ­ch máº«u 5000 cÃ¢u default Ä‘á»ƒ tÃ¬m tá»« khÃ³a má»›i
        analyze_sample = default_questions_for_analysis[:5000]
        analyze_unclassified(analyze_sample)

    # --- XUáº¤T Káº¾T QUáº¢ ---
    print("\n" + "="*60)
    print("ğŸ‘‡ COPY TOÃ€N Bá»˜ ÄOáº N DÆ¯á»šI ÄÃ‚Y VÃ€O FILE: conversation_config.py ğŸ‘‡")
    print("="*60 + "\n")
    
    print("TOPIC_SUGGESTIONS = {")
    for topic, questions in suggestions_map.items():
        if not questions:
            # Fallback náº¿u khÃ´ng tÃ¬m tháº¥y
            kw = TOPIC_KEYWORDS.get(topic, ["phÃ¡p luáº­t"])[0]
            questions = [f"Quy Ä‘á»‹nh vá» {kw}", f"Luáº­t {kw} má»›i nháº¥t", f"TÆ° váº¥n {kw}", f"Thá»§ tá»¥c liÃªn quan {kw}"]
        
        selected_questions = questions[:4]
        if len(questions) > 4:
            selected_questions = random.sample(questions, 4)

        print(f'    "{topic}": [')
        for q in selected_questions:
            print(f'        "{q}",')
        print('    ],')
    print("}")
    print("\n" + "="*60)

if __name__ == "__main__":
    main()